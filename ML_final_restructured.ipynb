{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UroqfV-fzpBA"
      },
      "source": [
        "# UNSW NB15 Hierarchical Intrusion Detection Classifier\n",
        "\n",
        "## Overview\n",
        "This notebook implements a Random Forest-based hierarchical classifier for intrusion detection using the UNSW-NB15 dataset.\n",
        "\n",
        "---\n",
        "\n",
        "## Architecture\n",
        "* **Model A (Binary):** Benign (0) vs. Malicious (1) (Stage 1)\n",
        "* **Model B (DoS Detector):** DoS (1) vs. Other attacks (2) (Stage 2, applied only to malicious traffic)\n",
        "* **Model C (Flat Tri-class):** Single-stage classifier (Benign/DoS/Other)\n",
        "* **Hierarchical Model:** Combined evaluation derived from Model A and Model B (Benign/DoS/Other)\n",
        "\n",
        "---\n",
        "\n",
        "## Key Features\n",
        "* **7-feature schema:** `['proto', 'service', 'spkts', 'dpkts', 'sbytes', 'dbytes', 'dur']`\n",
        "* Categorical features (`proto`, `service`) encoded with `OrdinalEncoder`\n",
        "* Numeric features passed through unchanged\n",
        "* **SMOTENC** oversampling applied for class imbalance\n",
        "* Precision-targeted thresholds for deployment\n",
        "* Hierarchical prediction pipeline\n",
        "\n",
        "---\n",
        "\n",
        "## 1. Dataset\n",
        "* **Source:** [UNSW-NB15](https://www.unsw.adfa.edu.au/unsw-canberra-cyber/cybersecurity/ADFA-NB15-Datasets/)\n",
        "* **Size:** ~257,000 records\n",
        "* **Classes:**\n",
        "    * Benign (0)\n",
        "    * DoS (1)\n",
        "    * Other attacks (2) (all other attack categories combined)\n",
        "\n",
        "---\n",
        "\n",
        "## 2. Preprocessing\n",
        "* Replace missing or invalid `proto` or `service` with `'unknown'`\n",
        "* Encode categorical features (`proto`, `service`) with `OrdinalEncoder`\n",
        "* Keep numeric features as-is (passthrough)\n",
        "* Drop any features not in `selected_features`\n",
        "* **SMOTENC** oversampling for training data\n",
        "\n",
        "---\n",
        "\n",
        "## 3. Model Training\n",
        "* **Model A:** Binary Random Forest (Malicious vs. Benign)\n",
        "* **Model B:** Random Forest (DoS vs. Other attacks)\n",
        "* **Model C:** Flat Random Forest tri-class classifier\n",
        "* **Thresholds:**\n",
        "    * F1-tuned for evaluation\n",
        "    * Precision-targeted for deployment\n",
        "\n",
        "---\n",
        "\n",
        "## 4. Model Evaluation\n",
        "* **Metrics:** ROC-AUC, PR-AUC, Precision, Recall, F1-score, Confusion matrices\n",
        "* Evaluated for both flat and hierarchical models\n",
        "\n",
        "---\n",
        "\n",
        "## 5. Model Artifacts\n",
        "\n",
        "| Artifact | Description |\n",
        "| :--- | :--- |\n",
        "| `rf_bin.joblib` | Trained binary classifier (Model A) |\n",
        "| `bin_threshold.json` | Precision-targeted threshold for Model A (deployment) |\n",
        "| `rf_dos_vs_other.joblib` | Trained classifier for DoS vs Other (Model B) |\n",
        "| `dos_threshold.json` | Deployment threshold for Model B |\n",
        "| `rf_tri.joblib` | Flat tri-class classifier (Model C) |\n",
        "| `features.json` | Ordered list of features used in all models |\n",
        "| `metrics_*.json` | Evaluation metrics (F1, ROC-AUC, PR-AUC, confusion matrices) |\n",
        "\n",
        "Artifacts are saved using `joblib` for models and JSON for thresholds, features, and metrics.\n",
        "\n",
        "---\n",
        "\n",
        "## 6. Prediction Utilities\n",
        "* Functions to load saved models and thresholds for flat or hierarchical inference\n",
        "* **Flat prediction:** Model A + Model C\n",
        "* **Hierarchical prediction:** Model A → Model B\n",
        "* Can export predictions to CSV for batch inference\n",
        "\n",
        "---\n",
        "\n",
        "## 7. Example Usage\n",
        "\n",
        "```python\n",
        "# Sample input\n",
        "df_sample = df_test[selected_features].head(5)\n",
        "\n",
        "# Flat predictions (binary + tri-class)\n",
        "pred_flat = predict_from_df(df_sample, mode=\"both\")\n",
        "print(pred_flat)\n",
        "\n",
        "# Hierarchical predictions (Model A → Model B)\n",
        "pred_hier = predict_hier_from_df(df_sample)\n",
        "print(pred_hier)\n",
        "\n",
        "# Save predictions to CSV\n",
        "save_predictions_csv(df_sample, \"predictions_demo.csv\", mode=\"hier\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0FMKDmuHzpBE"
      },
      "source": [
        "## Section 1: Initial Setup & Configuration"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iaiuEW9ZzpBF",
        "outputId": "f70b0b8f-7a5d-46a3-fa06-445fab16b58a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "imbalanced-learn already available.\n"
          ]
        }
      ],
      "source": [
        "# -------------------------\n",
        "# Import Libraries\n",
        "# -------------------------\n",
        "\n",
        "import os, json, warnings\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "from sklearn.model_selection import train_test_split, RandomizedSearchCV, StratifiedKFold\n",
        "from sklearn.preprocessing import OrdinalEncoder\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.metrics import (\n",
        "    roc_auc_score, average_precision_score, f1_score,\n",
        "    precision_recall_fscore_support, confusion_matrix, classification_report,\n",
        "    precision_recall_curve\n",
        ")\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "import joblib\n",
        "\n",
        "# -------------------------\n",
        "# Install Dependencies\n",
        "# -------------------------\n",
        "# imbalanced-learn is required for SMOTENC (handling mixed-type imbalance).\n",
        "\n",
        "try:\n",
        "    import imblearn\n",
        "    print(\"imbalanced-learn already available.\")\n",
        "except ImportError:\n",
        "    %pip install -q imbalanced-learn\n",
        "\n",
        "# -------------------------\n",
        "# SMOTENC Setup\n",
        "# -------------------------\n",
        "# SMOTENC handles categorical + numerical oversampling for class imbalance.\n",
        "\n",
        "try:\n",
        "    from imblearn.over_sampling import SMOTENC\n",
        "    from imblearn.pipeline import Pipeline as ImbPipeline\n",
        "    IMB_OK = True\n",
        "except ImportError:\n",
        "    IMB_OK = False\n",
        "    print(\"imblearn unavailable – proceeding without SMOTENC.\")\n",
        "\n",
        "# Suppress warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "# Set a global random state for reproducibility\n",
        "RANDOM_STATE = 42\n",
        "np.random.seed(RANDOM_STATE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YKoAhOGgzpBG",
        "outputId": "926b0444-f9a5-448b-e40e-9fe78f3644a4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive/\n"
          ]
        }
      ],
      "source": [
        "# Import the Google Colab drive module.\n",
        "from google.colab import drive\n",
        "# Mount Google Drive to access files.\n",
        "drive.mount('/content/gdrive/', force_remount=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "Epxu9t1MzpBG"
      },
      "outputs": [],
      "source": [
        "# Copy the dataset from Google Drive to the current working directory.\n",
        "# The dataset is expected to be in 'gdrive/My Drive/NSA/Dataset'.\n",
        "# The -r flag ensures recursive copying for directories.\n",
        "!cp -r gdrive/My\\ Drive/NSA/Dataset ."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "-6gnLMn9zpBH"
      },
      "outputs": [],
      "source": [
        "# -------------------------\n",
        "# File Paths and Parameters\n",
        "# -------------------------\n",
        "\n",
        "TRAIN_CSV = \"Dataset/UNSW_NB15_training-set.csv\"\n",
        "TEST_CSV  = \"Dataset/UNSW_NB15_testing-set.csv\"\n",
        "\n",
        "# The specific chosen attack category to be spotlighted for this classification model\n",
        "SPECIFIC_ATTACK = \"DoS\"\n",
        "\n",
        "# The model training uses a 7-feature schema for simplicity and focus.\n",
        "selected_features = ['proto','service','spkts','dpkts','sbytes','dbytes','dur']\n",
        "# Categorical features\n",
        "categorical_feature_names = ['proto','service']\n",
        "# Numerical features\n",
        "numeric_feature_names     = ['spkts','dpkts','sbytes','dbytes','dur']\n",
        "\n",
        "# Toggle whether to use SMOTENC-based oversampling for handling class imbalance.\n",
        "USE_SMOTENC = True\n",
        "\n",
        "# Initialize DO_SEARCH flag for hyperparameter tuning. Default to False for quicker runs.\n",
        "# Set to True if hyperparameter tuning (RandomizedSearchCV) is desired.\n",
        "DO_SEARCH = False\n",
        "\n",
        "# Define target precision for demonstration and deployment\n",
        "TARGET_PRECISION_FOR_DEMO = 0.90\n",
        "DOS_TARGET_PRECISION_FOR_DEMO = 0.80"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4Bg_wpzrzpBH"
      },
      "source": [
        "## Section 2: Data Loading & Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W4094Ok2zpBH",
        "outputId": "cd57b2f6-8d5c-4f96-ec62-8bb50baaaa02"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train: (175341, 45)  Test: (82332, 45)\n",
            "Cols: ['id', 'dur', 'proto', 'service', 'state', 'spkts', 'dpkts', 'sbytes', 'dbytes', 'rate', 'sttl', 'dttl', 'sload', 'dload', 'sloss'] ... (total: 45 )\n"
          ]
        }
      ],
      "source": [
        "# -------------------------\n",
        "# Data Loading and Cleaning\n",
        "# -------------------------\n",
        "\n",
        "def load_unsw(train_csv, test_csv):\n",
        "    \"\"\"\n",
        "    Loads the UNSW-NB15 training and testing datasets from CSV files.\n",
        "    Performs initial cleaning by replacing missing or invalid 'service' and 'proto'\n",
        "    values with 'unknown'.\n",
        "\n",
        "    Args:\n",
        "        train_csv (str): Path to the training CSV file.\n",
        "        test_csv (str): Path to the testing CSV file.\n",
        "\n",
        "    Returns:\n",
        "        tuple: A tuple containing two pandas DataFrames (df_tr, df_te)\n",
        "               for the training and testing data respectively.\n",
        "    \"\"\"\n",
        "    df_tr = pd.read_csv(train_csv)\n",
        "    df_te = pd.read_csv(test_csv)\n",
        "    # Replace missing or invalid service/protocol values\n",
        "    for df in (df_tr, df_te):\n",
        "        if 'service' in df.columns:\n",
        "            df['service'] = df['service'].replace('-', 'unknown').fillna('unknown')\n",
        "        if 'proto' in df.columns:\n",
        "            df['proto'] = df['proto'].fillna('unknown')\n",
        "    return df_tr, df_te\n",
        "\n",
        "# Load dataset\n",
        "df_train, df_test = load_unsw(TRAIN_CSV, TEST_CSV)\n",
        "\n",
        "print(\"Train:\", df_train.shape, \" Test:\", df_test.shape)\n",
        "print(\"Cols:\", list(df_train.columns)[:15], \"... (total:\", len(df_train.columns), \")\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5Y_8pqufzpBI",
        "outputId": "f0586336-9325-4b1d-cbb5-16d7c8238807"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "y_bin (train):\n",
            " label\n",
            "1    119341\n",
            "0     56000\n",
            "Name: count, dtype: int64 \n",
            "\n",
            "y_tri (train) [0=Benign,1=DoS,2=Other]:\n",
            " attack_cat\n",
            "0     56000\n",
            "1     12264\n",
            "2    107077\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "# -------------------------\n",
        "# Label Engineering\n",
        "# -------------------------\n",
        "\n",
        "# Binary label: 0 = Benign, 1 = Malicious\n",
        "y_bin_train = df_train['label'].astype(int)\n",
        "y_bin_test  = df_test['label'].astype(int)\n",
        "\n",
        "# Label mapping:\n",
        "#   0 = Benign, 1 = DoS, 2 = Other attacks\n",
        "# This function maps the 'attack_cat' string labels to integer labels\n",
        "def map_tri(cat: str) -> int:\n",
        "    if cat == 'Normal': return 0  # Benign\n",
        "    if cat == SPECIFIC_ATTACK: return 1 # DoS attack\n",
        "    return 2                      # All other attack categories\n",
        "\n",
        "y_tri_train = df_train['attack_cat'].apply(map_tri).astype(int)\n",
        "y_tri_test  = df_test['attack_cat'].apply(map_tri).astype(int)\n",
        "\n",
        "# Input features (X)\n",
        "# Select only the predefined 'selected_features' for model training.\n",
        "X_train = df_train[selected_features].copy()\n",
        "X_test  = df_test[selected_features].copy()\n",
        "\n",
        "print(\"y_bin (train):\\n\", y_bin_train.value_counts(), \"\\n\")\n",
        "print(\"y_tri (train) [0=Benign,1=DoS,2=Other]:\\n\", y_tri_train.value_counts().sort_index())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "CMNf_W-YzpBI"
      },
      "outputs": [],
      "source": [
        "# -------------------------\n",
        "# Preprocessing\n",
        "# -------------------------\n",
        "# ColumnTransformer for preprocessing:\n",
        "# - Categorical features ('proto', 'service') are encoded using OrdinalEncoder.\n",
        "#   'handle_unknown='use_encoded_value', unknown_value=-1' handles unseen categories\n",
        "#   by assigning them a specific value (-1).\n",
        "# - Numerical features are 'passthrough', meaning they are kept as is.\n",
        "# - 'remainder='drop'' ensures that any features not explicitly listed in transformers\n",
        "#   are dropped from the dataset.\n",
        "\n",
        "preprocessor = ColumnTransformer(\n",
        "    transformers=[\n",
        "        ('cat', OrdinalEncoder(handle_unknown='use_encoded_value', unknown_value=-1), categorical_feature_names),\n",
        "        ('num', 'passthrough', numeric_feature_names),\n",
        "    ],\n",
        "    remainder='drop'\n",
        ")\n",
        "\n",
        "categorical_features = [0, 1]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8o0kzP2AzpBI"
      },
      "source": [
        "## Section 3: Utility Functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "7hikElY3zpBJ"
      },
      "outputs": [],
      "source": [
        "# -------------------------\n",
        "# Threshold Selection Functions\n",
        "# -------------------------\n",
        "\n",
        "def pick_threshold_by_f1(scores: np.ndarray, y_true: np.ndarray, grid=None) -> float:\n",
        "    \"\"\"\n",
        "    Selects the classification threshold that maximizes the F1-score.\n",
        "\n",
        "    Args:\n",
        "        scores (np.ndarray): Predicted probabilities.\n",
        "        y_true (np.ndarray): True binary labels.\n",
        "        grid (np.ndarray, optional): Array of thresholds to check. If None, a default\n",
        "                                     grid from 0.05 to 0.95 is used.\n",
        "\n",
        "    Returns:\n",
        "        float: The threshold value that yields the highest F1-score.\n",
        "    \"\"\"\n",
        "    if grid is None:\n",
        "        grid = np.linspace(0.05, 0.95, 19)\n",
        "    best_t, best_f1 = 0.5, -1.0\n",
        "    for t in grid:\n",
        "        # Convert scores to binary predictions using the current threshold\n",
        "        pred = (scores >= t).astype(int)\n",
        "        # Calculate F1-score\n",
        "        f1 = f1_score(y_true, pred, zero_division=0)\n",
        "        # Update best threshold if current F1-score is higher\n",
        "        if f1 > best_f1:\n",
        "            best_f1, best_t = f1, t\n",
        "    return float(best_t)\n",
        "\n",
        "def pick_threshold_by_precision(scores: np.ndarray, y_true: np.ndarray, target_prec: float) -> float:\n",
        "    \"\"\"\n",
        "    Selects the lowest classification threshold that achieves at least the target precision.\n",
        "    Uses the precision-recall curve to find suitable thresholds.\n",
        "\n",
        "    Args:\n",
        "        scores (np.ndarray): Predicted probabilities.\n",
        "        y_true (np.ndarray): True binary labels.\n",
        "        target_prec (float): The minimum desired precision.\n",
        "\n",
        "    Returns:\n",
        "        float: The lowest threshold that meets the target precision.\n",
        "    \"\"\"\n",
        "    # Calculate precision, recall, and thresholds from the precision-recall curve.\n",
        "    prec, rec, thr = precision_recall_curve(y_true, scores)\n",
        "    chosen = None\n",
        "    for i in range(len(thr)):           # Note: len(thr) = len(prec) - 1\n",
        "        if prec[i] >= target_prec:\n",
        "            chosen = float(thr[i])\n",
        "            break\n",
        "    if chosen is None:\n",
        "        # Fallback to the strictest threshold if target precision isn't reached.\n",
        "        # If no thresholds are available, default to 0.5.\n",
        "        chosen = float(thr[-1]) if len(thr) else 0.5\n",
        "    return chosen"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "6HlbulmwzpBJ"
      },
      "outputs": [],
      "source": [
        "# -------------------------\n",
        "# Network Log Parsing Functions\n",
        "# -------------------------\n",
        "\n",
        "def zeek_conn_to_features_df(conn_log_path: str) -> pd.DataFrame:\n",
        "    \"\"\"\n",
        "    Parses a Zeek conn.log file (JSON format) and converts it into a pandas DataFrame\n",
        "    containing the selected features for model inference.\n",
        "\n",
        "    Args:\n",
        "        conn_log_path (str): Path to the Zeek conn.log file.\n",
        "\n",
        "    Returns:\n",
        "        pd.DataFrame: DataFrame with extracted features, ready for model input.\n",
        "    \"\"\"\n",
        "    rows = []\n",
        "    with open(conn_log_path, \"r\", encoding=\"utf-8\") as f:\n",
        "        for line in f:\n",
        "            if not line.strip():\n",
        "                continue\n",
        "            try:\n",
        "                d = json.loads(line)\n",
        "            except json.JSONDecodeError:\n",
        "                continue\n",
        "            # Extract relevant fields, handling missing keys with defaults\n",
        "            proto   = d.get('proto', 'unknown')\n",
        "            service = d.get('service', 'unknown') or 'unknown' # Handle empty string service as unknown\n",
        "            spkts   = d.get('orig_pkts', 0)\n",
        "            dpkts   = d.get('resp_pkts', 0)\n",
        "            sbytes  = d.get('orig_bytes', 0)\n",
        "            dbytes  = d.get('resp_bytes', 0)\n",
        "            dur     = d.get('duration', 0.0)\n",
        "            rows.append([proto, service, spkts, dpkts, sbytes, dbytes, dur])\n",
        "\n",
        "    df = pd.DataFrame(rows, columns=selected_features)\n",
        "    # Ensure correct data types\n",
        "    df['proto'] = df['proto'].astype(str)\n",
        "    df['service'] = df['service'].astype(str)\n",
        "    for c in ['spkts','dpkts','sbytes','dbytes']:\n",
        "        df[c] = pd.to_numeric(df[c], errors='coerce').fillna(0).astype(int)\n",
        "    df['dur'] = pd.to_numeric(df['dur'], errors='coerce').fillna(0.0).astype(float)\n",
        "    return df\n",
        "\n",
        "def suricata_eve_to_features_df(eve_json_path: str) -> pd.DataFrame:\n",
        "    \"\"\"\n",
        "    Parses a Suricata EVE JSON log file and extracts flow-related information\n",
        "    to create a pandas DataFrame suitable for model inference.\n",
        "\n",
        "    Args:\n",
        "        eve_json_path (str): Path to the Suricata EVE JSON file.\n",
        "\n",
        "    Returns:\n",
        "        pd.DataFrame: DataFrame with extracted features, ready for model input.\n",
        "    \"\"\"\n",
        "    rows = []\n",
        "    with open(eve_json_path, \"r\", encoding=\"utf-8\") as f:\n",
        "        for line in f:\n",
        "            if not line.strip():\n",
        "                continue\n",
        "            try:\n",
        "                d = json.loads(line)\n",
        "            except json.JSONDecodeError:\n",
        "                continue\n",
        "            # Only process 'flow' events\n",
        "            if d.get('event_type') != 'flow':\n",
        "                continue\n",
        "            flow = d.get('flow', {})\n",
        "            # Extract relevant fields, handling missing keys with defaults\n",
        "            proto   = d.get('proto', 'unknown')\n",
        "            service = d.get('app_proto', 'unknown') or 'unknown' # Handle empty string app_proto as unknown\n",
        "            spkts   = flow.get('pkts_toserver', 0)\n",
        "            dpkts   = flow.get('pkts_toclient', 0)\n",
        "            sbytes  = flow.get('bytes_toserver', 0)\n",
        "            dbytes  = flow.get('bytes_toclient', 0)\n",
        "            dur     = flow.get('duration', 0.0)\n",
        "            rows.append([proto, service, spkts, dpkts, sbytes, dbytes, dur])\n",
        "\n",
        "    df = pd.DataFrame(rows, columns=selected_features)\n",
        "    # Ensure correct data types\n",
        "    df['proto'] = df['proto'].astype(str)\n",
        "    df['service'] = df['service'].astype(str)\n",
        "    for c in ['spkts','dpkts','sbytes','dbytes']:\n",
        "        df[c] = pd.to_numeric(df[c], errors='coerce').fillna(0).astype(int)\n",
        "    df['dur'] = pd.to_numeric(df['dur'], errors='coerce').fillna(0.0).astype(float)\n",
        "    return df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4eHAp7vRzpBJ"
      },
      "source": [
        "## Section 4: Model A - Binary Classifier (Stage 1 of Hierarchy)\n",
        "\n",
        "Model A distinguishes between Benign and Malicious traffic. This is the first stage of the hierarchical classifier."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fylp9NgvzpBJ",
        "outputId": "22a5aa7b-6464-44c5-d0e8-b807b96b9b50"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== Model A (Binary: Benign vs Malicious) (TEST) – F1-tuned threshold ===\n",
            "Threshold(F1): 0.250\n",
            "ROC-AUC:       0.9717 | PR-AUC: 0.9775\n",
            "Precision:     0.7902 | Recall: 0.9758 | F1: 0.8732\n",
            "Confusion [[TN,FP],[FN,TP]]:\n",
            " [[25253 11747]\n",
            " [ 1099 44233]]\n"
          ]
        }
      ],
      "source": [
        "# -------------------------\n",
        "# Model A: Binary Classifier (Benign vs Malicious)\n",
        "#   - This is the first step of the hierarchical model, classifying traffic as either Benign or Malicious.\n",
        "# -------------------------\n",
        "\n",
        "# Split the training data into training and validation sets for model tuning and threshold selection.\n",
        "# stratify=y_bin_train ensures that the proportion of classes is maintained in both splits for class imabalance cases.\n",
        "X_tr, X_val, y_tr, y_val = train_test_split(\n",
        "    X_train, y_bin_train, test_size=0.2, random_state=RANDOM_STATE, stratify=y_bin_train\n",
        ")\n",
        "\n",
        "# Initialize the Random Forest Classifier for the binary classification task.\n",
        "# n_estimators: Number of trees in the forest.\n",
        "# class_weight='balanced_subsample': Automatically adjusts weights inversely proportional to class frequencies\n",
        "#                                    in the subsample to deal with class imbalance.\n",
        "rf_model_bin = RandomForestClassifier(\n",
        "    n_estimators=500, max_depth=None, min_samples_leaf=1,\n",
        "    max_features='sqrt', n_jobs=-1, class_weight='balanced_subsample',\n",
        "    random_state=RANDOM_STATE\n",
        ")\n",
        "\n",
        "# Construct the pipeline for Model A (binary classifier).\n",
        "# If SMOTENC is enabled and available, use ImbPipeline which integrates SMOTENC.\n",
        "if USE_SMOTENC and IMB_OK:\n",
        "    bin_pipeline = ImbPipeline(steps=[\n",
        "        ('pre', preprocessor), # Apply preprocessing (OrdinalEncoder for cat, passthrough for num)\n",
        "        ('smote', SMOTENC(random_state=RANDOM_STATE, categorical_features=categorical_features, k_neighbors=5)), # Apply SMOTENC for oversampling\n",
        "        ('rf', rf_model_bin) # Random Forest classifier\n",
        "    ])\n",
        "else:\n",
        "    bin_pipeline = Pipeline(steps=[('pre', preprocessor), ('rf', rf_model_bin)])\n",
        "\n",
        "# -------------------------\n",
        "# Model A: F1-tuned Threshold\n",
        "# -------------------------\n",
        "\n",
        "# Train the binary classification pipeline (Model A) on the training data.\n",
        "bin_pipeline.fit(X_tr, y_tr)\n",
        "\n",
        "# Predict probabilities on the validation set to determine the optimal threshold.\n",
        "val_scores = bin_pipeline.predict_proba(X_val)[:, 1] # Probability of the positive class (Malicious)\n",
        "\n",
        "# Pick the threshold that maximizes the F1-score on the validation set.\n",
        "bin_threshold_f1 = pick_threshold_by_f1(val_scores, y_val)\n",
        "\n",
        "# Evaluate Model A on the independent test set using the F1-tuned threshold.\n",
        "test_scores = bin_pipeline.predict_proba(X_test)[:, 1]\n",
        "test_pred_bin_f1 = (test_scores >= bin_threshold_f1).astype(int)\n",
        "\n",
        "# Evaluation metrics for Model A (binary classifier).\n",
        "bin_roc = roc_auc_score(y_bin_test, test_scores) # ROC AUC\n",
        "bin_ap  = average_precision_score(y_bin_test, test_scores) # Average Precision score\n",
        "p_f1,r_f1,f1_f1,_ = precision_recall_fscore_support(y_bin_test, test_pred_bin_f1, average='binary', zero_division=0) # Precision, Recall, F1-score\n",
        "bin_cm_f1 = confusion_matrix(y_bin_test, test_pred_bin_f1) # Confusion Matrix\n",
        "\n",
        "print(\"=== Model A (Binary: Benign vs Malicious) (TEST) – F1-tuned threshold ===\")\n",
        "print(f\"Threshold(F1): {bin_threshold_f1:.3f}\")\n",
        "print(f\"ROC-AUC:       {bin_roc:.4f} | PR-AUC: {bin_ap:.4f}\")\n",
        "print(f\"Precision:     {p_f1:.4f} | Recall: {r_f1:.4f} | F1: {f1_f1:.4f}\")\n",
        "print(\"Confusion [[TN,FP],[FN,TP]]:\\n\", bin_cm_f1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FchLDxVazpBK",
        "outputId": "65299f96-a0f9-4341-8d45-f958efec5527"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Skipping hyperparam search (set DO_SEARCH=True to enable).\n"
          ]
        }
      ],
      "source": [
        "# -------------------------\n",
        "# Optional: Hyperparameter Search\n",
        "# -------------------------\n",
        "\n",
        "if DO_SEARCH:\n",
        "    # Parameters\n",
        "    param_dist = {\n",
        "        'rf__n_estimators': [300, 500, 700], # Number of trees\n",
        "        'rf__max_depth': [None, 8, 12, 20],   # Maximum depth of each tree\n",
        "        'rf__min_samples_leaf': [1, 2, 4],    # Minimum number of samples required to be at a leaf node\n",
        "        'rf__max_features': ['sqrt', 'log2']  # Number of features to consider when looking for the best split\n",
        "    }\n",
        "    # StratifiedKFold for cross-validation to maintain class balance.\n",
        "    cv = StratifiedKFold(n_splits=3, shuffle=True, random_state=RANDOM_STATE)\n",
        "    # RandomizedSearchCV to search for the best hyperparameters.\n",
        "    search = RandomizedSearchCV(\n",
        "        bin_pipeline, # The pipeline to tune\n",
        "        param_distributions=param_dist, # The parameter space to search\n",
        "        n_iter=6, # Number of parameter settings that are sampled\n",
        "        scoring='f1', # Metric to optimize (F1-score is chosen here)\n",
        "        cv=cv, # Cross-validation strategy\n",
        "        n_jobs=-1, # Use all available cores\n",
        "        verbose=1, # Display progress messages\n",
        "        random_state=RANDOM_STATE # For reproducibility\n",
        "    )\n",
        "    # Fit the RandomizedSearchCV to the training data to find the best model.\n",
        "    search.fit(X_tr, y_tr)\n",
        "    # Update the binary pipeline with the best estimator found by the search.\n",
        "    bin_pipeline = search.best_estimator_\n",
        "    # Re-evaluate on the validation set using the best pipeline to re-determine the F1-tuned threshold.\n",
        "    val_scores = bin_pipeline.predict_proba(X_val)[:, 1]\n",
        "    bin_threshold_f1 = pick_threshold_by_f1(val_scores, y_val)\n",
        "    # Predict probabilities on the test set using the best pipeline.\n",
        "    test_scores = bin_pipeline.predict_proba(X_test)[:, 1]\n",
        "    print(\"Search best params:\", search.best_params_)\n",
        "else:\n",
        "    print(\"Skipping hyperparam search (set DO_SEARCH=True to enable).\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wg54_rj2zpBK",
        "outputId": "88c1d92e-7304-49fb-e905-327f75b7609e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== Model A (Binary: Benign vs Malicious) (TEST) – Precision-targeted threshold (for Deployment) ===\n",
            "Target precision: 0.9\n",
            "Threshold(Prec):  0.662\n",
            "Precision:        0.9000 | Recall: 0.9316 | F1: 0.9155\n",
            "Confusion [[TN,FP],[FN,TP]]:\n",
            " [[32310  4690]\n",
            " [ 3102 42230]]\n",
            "\n",
            "BIN_THRESHOLD_FOR_DEPLOY (for Model A in Hierarchical Prediction) = 0.6623993531975984\n"
          ]
        }
      ],
      "source": [
        "# -------------------------\n",
        "# Model A: Precision-Targeted Threshold (For Deployment)\n",
        "# -------------------------\n",
        "\n",
        "# Determine the binary classification threshold based on a target precision.\n",
        "# This threshold prioritizes a certain level of precision, which can be critical in security applications.\n",
        "# This is the deployment threshold for Model A, used as the first step in the hierarchical prediction.\n",
        "bin_threshold_prec = pick_threshold_by_precision(test_scores, y_bin_test, TARGET_PRECISION_FOR_DEMO)\n",
        "\n",
        "# Apply the precision-targeted threshold to the test set scores to get binary predictions.\n",
        "test_pred_bin_prec = (test_scores >= bin_threshold_prec).astype(int)\n",
        "\n",
        "# Calculate evaluation metrics (Precision, Recall, F1-score) for the binary predictions\n",
        "# obtained with the precision-targeted threshold.\n",
        "p_pr,r_pr,f1_pr,_ = precision_recall_fscore_support(y_bin_test, test_pred_bin_prec, average='binary', zero_division=0)\n",
        "\n",
        "# Confusion matrix.\n",
        "bin_cm_prec = confusion_matrix(y_bin_test, test_pred_bin_prec)\n",
        "\n",
        "print(\"=== Model A (Binary: Benign vs Malicious) (TEST) – Precision-targeted threshold (for Deployment) ===\")\n",
        "print(f\"Target precision: {TARGET_PRECISION_FOR_DEMO}\")\n",
        "print(f\"Threshold(Prec):  {bin_threshold_prec:.3f}\")\n",
        "print(f\"Precision:        {p_pr:.4f} | Recall: {r_pr:.4f} | F1: {f1_pr:.4f}\")\n",
        "print(\"Confusion [[TN,FP],[FN,TP]]:\\n\", bin_cm_prec)\n",
        "\n",
        "# Store the precision-targeted threshold as the deployment threshold for Model A.\n",
        "BIN_THRESHOLD_FOR_DEPLOY = float(bin_threshold_prec)\n",
        "print(\"\\nBIN_THRESHOLD_FOR_DEPLOY (for Model A in Hierarchical Prediction) =\", BIN_THRESHOLD_FOR_DEPLOY)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DpVJBUdfzpBK"
      },
      "source": [
        "## Section 5: Model B - DoS vs Other Classifier (Stage 2 of Hierarchy)\n",
        "\n",
        "Model B is trained on malicious traffic only and distinguishes between DoS attacks and other attack types."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DIYJ91AJzpBK",
        "outputId": "690b0d85-f7b0-43dd-bbd3-426f363f6e96"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== Model B (DoS vs Other) – malicious TEST subset @ precision-target ===\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       Other       0.91      1.00      0.95     41243\n",
            "         DoS       0.77      0.04      0.07      4089\n",
            "\n",
            "    accuracy                           0.91     45332\n",
            "   macro avg       0.84      0.52      0.51     45332\n",
            "weighted avg       0.90      0.91      0.87     45332\n",
            "\n",
            "Confusion matrix [rows=Actual Other,DoS; cols=Pred Other,DoS]:\n",
            " [[41197    46]\n",
            " [ 3939   150]]\n",
            "\n",
            "DOS_THRESHOLD_FOR_DEPLOY (for Model B in Hierarchical Prediction) = 0.9716666666666667\n"
          ]
        }
      ],
      "source": [
        "# -------------------------\n",
        "# Model B: DoS vs Other Attacks Classifier\n",
        "#   - This model is trained to distinguish between DoS and Other attacks ONLY within the malicious traffic\n",
        "#     identified by Model A.\n",
        "# -------------------------\n",
        "\n",
        "# Split the original dataframes to create malicious subsets for training and testing Model B.\n",
        "# This focuses only on instances identified as malicious by the binary label (y_bin_train/test == 1).\n",
        "mal_train = df_train[y_bin_train == 1].copy()\n",
        "mal_test  = df_test[y_bin_test  == 1].copy()\n",
        "\n",
        "# Extract selected features for the malicious subsets.\n",
        "X_mal_train = mal_train[selected_features].copy()\n",
        "X_mal_test  = mal_test[selected_features].copy()\n",
        "\n",
        "# Create binary labels for Model B classifier: 1 for SPECIFIC_ATTACK (e.g., DoS), 0 for Other malicious attacks.\n",
        "y_dos_train = (mal_train['attack_cat'] == SPECIFIC_ATTACK).astype(int)\n",
        "y_dos_test  = (mal_test['attack_cat']  == SPECIFIC_ATTACK).astype(int)\n",
        "\n",
        "# Initialize the Random Forest Classifier for Model B (DoS vs. Other) classification task.\n",
        "rf_model_dos = RandomForestClassifier(\n",
        "    n_estimators=600, max_depth=None, min_samples_leaf=1,\n",
        "    max_features='sqrt', n_jobs=-1, class_weight='balanced_subsample',\n",
        "    random_state=RANDOM_STATE\n",
        ")\n",
        "\n",
        "# Construct the pipeline for Model B classifier.\n",
        "# It includes preprocessing and optionally SMOTENC, but with slightly tighter k_neighbors for SMOTENC.\n",
        "if USE_SMOTENC and IMB_OK:\n",
        "    dos_pipeline = ImbPipeline(steps=[\n",
        "        ('pre', preprocessor),\n",
        "        ('smote', SMOTENC(random_state=RANDOM_STATE, categorical_features=categorical_features, k_neighbors=3)),  # slightly tighter\n",
        "        ('rf', rf_model_dos)\n",
        "    ])\n",
        "else:\n",
        "    dos_pipeline = Pipeline(steps=[('pre', preprocessor), ('rf', rf_model_dos)])\n",
        "\n",
        "# Split the malicious training data into training and validation sets for Model B tuning.\n",
        "# Stratification is used to maintain the proportion of DoS vs. Other attacks.\n",
        "Xd_tr, Xd_val, yd_tr, yd_val = train_test_split(\n",
        "    X_mal_train, y_dos_train, test_size=0.2, random_state=RANDOM_STATE, stratify=y_dos_train\n",
        ")\n",
        "\n",
        "# Train the Model B (DoS vs. Other) classification pipeline.\n",
        "dos_pipeline.fit(Xd_tr, yd_tr)\n",
        "\n",
        "# Predict probabilities on the validation set to determine the optimal threshold for Model B.\n",
        "dos_val_scores = dos_pipeline.predict_proba(Xd_val)[:,1]\n",
        "\n",
        "# Refine the DoS deployment threshold using the target precision on the validation set.\n",
        "DOS_THRESHOLD_FOR_DEPLOY = pick_threshold_by_precision(dos_val_scores, yd_val, DOS_TARGET_PRECISION_FOR_DEMO)\n",
        "\n",
        "# Quick check on malicious TEST subset using the newly defined threshold\n",
        "\n",
        "# Predict probabilities on the malicious test subset for Model B.\n",
        "dos_test_scores = dos_pipeline.predict_proba(X_mal_test)[:, 1]\n",
        "# Apply the precision-targeted threshold to get binary predictions for DoS vs Other.\n",
        "dos_test_pred   = (dos_test_scores >= DOS_THRESHOLD_FOR_DEPLOY).astype(int)\n",
        "\n",
        "print(\"=== Model B (DoS vs Other) – malicious TEST subset @ precision-target ===\")\n",
        "print(classification_report(y_dos_test, dos_test_pred, zero_division=0, target_names=['Other','DoS']))\n",
        "print(\"Confusion matrix [rows=Actual Other,DoS; cols=Pred Other,DoS]:\\n\", confusion_matrix(y_dos_test, dos_test_pred))\n",
        "\n",
        "print(\"\\nDOS_THRESHOLD_FOR_DEPLOY (for Model B in Hierarchical Prediction) =\", DOS_THRESHOLD_FOR_DEPLOY)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zpjUKjuDzpBK"
      },
      "source": [
        "## Section 6: Model C - Flat Tri-class Classifier\n",
        "\n",
        "Model C is a single-stage classifier that directly predicts Benign/DoS/Other in one step (non-hierarchical)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MT571MfAzpBK",
        "outputId": "f2feeec3-08b9-4f4b-b3fb-a4332cf3b4e8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== Model C (Flat Tri-class: Benign vs DoS vs Other) (TEST) ===\n",
            "              precision    recall  f1-score       support\n",
            "0              0.936682  0.802838  0.864611  37000.000000\n",
            "1              0.300595  0.506725  0.377345   4089.000000\n",
            "2              0.798038  0.846083  0.821358  41243.000000\n",
            "accuracy       0.809794  0.809794  0.809794      0.809794\n",
            "macro avg      0.678438  0.718549  0.687771  82332.000000\n",
            "weighted avg   0.835639  0.809794  0.818744  82332.000000\n",
            "\n",
            "Confusion matrix rows=Actual[Benign,DoS,Other], cols=Pred[Benign,DoS,Other]:\n",
            "[[29705   423  6872]\n",
            " [   58  2072  1959]\n",
            " [ 1950  4398 34895]]\n"
          ]
        }
      ],
      "source": [
        "# -------------------------\n",
        "# Model C: Flat Tri-class Classifier (Benign vs DoS vs Other)\n",
        "# -------------------------\n",
        "\n",
        "# Initialize Random Forest Classifier.\n",
        "rf_model_tri = RandomForestClassifier(\n",
        "    n_estimators=600, max_depth=None, min_samples_leaf=1,\n",
        "    max_features='sqrt', n_jobs=-1, class_weight='balanced_subsample',\n",
        "    random_state=RANDOM_STATE\n",
        ")\n",
        "\n",
        "# Initialize pipeline for Model C.\n",
        "if USE_SMOTENC and IMB_OK:\n",
        "    tri_pipeline = ImbPipeline(steps=[\n",
        "        ('pre', preprocessor),\n",
        "        ('smote', SMOTENC(random_state=RANDOM_STATE, categorical_features=categorical_features, k_neighbors=5)),\n",
        "        ('rf', rf_model_tri)\n",
        "    ])\n",
        "else:\n",
        "    tri_pipeline = Pipeline(steps=[('pre', preprocessor), ('rf', rf_model_tri)])\n",
        "\n",
        "# Train.\n",
        "tri_pipeline.fit(X_train, y_tri_train)\n",
        "\n",
        "# Predict.\n",
        "tri_pred_test = tri_pipeline.predict(X_test)\n",
        "\n",
        "# Confusion matrix.\n",
        "tri_cm_flat = confusion_matrix(y_tri_test, tri_pred_test)\n",
        "\n",
        "print(\"=== Model C (Flat Tri-class: Benign vs DoS vs Other) (TEST) ===\")\n",
        "print(pd.DataFrame(\n",
        "    classification_report(y_tri_test, tri_pred_test, output_dict=True, zero_division=0)\n",
        ").T[['precision','recall','f1-score','support']])\n",
        "print(\"\\nConfusion matrix rows=Actual[Benign,DoS,Other], cols=Pred[Benign,DoS,Other]:\")\n",
        "print(tri_cm_flat)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ONbaL8JkzpBK"
      },
      "source": [
        "## Section 7: Hierarchical Model - Combined Evaluation (A → B)\n",
        "\n",
        "This section demonstrates the complete hierarchical pipeline: Model A identifies malicious traffic, then Model B classifies it as DoS or Other."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZuauLbeyzpBL",
        "outputId": "41c0f3c2-22ad-4aa6-9b9e-2680bba367d3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== Tri-class (HIERARCHICAL: Model A → Model B) – TEST ===\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "      Benign       0.91      0.87      0.89     37000\n",
            "         DoS       0.70      0.02      0.03      4089\n",
            "       Other       0.82      0.93      0.87     41243\n",
            "\n",
            "    accuracy                           0.86     82332\n",
            "   macro avg       0.81      0.61      0.60     82332\n",
            "weighted avg       0.85      0.86      0.84     82332\n",
            "\n",
            "Confusion matrix rows=Actual[Benign,DoS,Other], cols=Pred[Benign,DoS,Other]:\n",
            " [[32310     0  4690]\n",
            " [  125    62  3902]\n",
            " [ 2977    27 38239]]\n"
          ]
        }
      ],
      "source": [
        "# -------------------------\n",
        "# Hierarchical Model\n",
        "#   - This section combines Model A and Model B predictions to form the final hierarchical tri-class output.\n",
        "#   - Model A (Binary Classifier) runs first, and only malicious instances are passed to Model B.\n",
        "# -------------------------\n",
        "\n",
        "# Re-calculate binary classification scores for the entire test set using Model A.\n",
        "bin_scores_test = bin_pipeline.predict_proba(X_test)[:, 1]\n",
        "\n",
        "# Identify instances classified as malicious by Model A using its deployed binary threshold.\n",
        "is_malicious    = (bin_scores_test >= BIN_THRESHOLD_FOR_DEPLOY)\n",
        "\n",
        "# Initialize the array for hierarchical tri-class predictions.\n",
        "# Default all instances to Benign (0).\n",
        "tri_pred_hier = np.zeros(len(X_test), dtype=int)  # 0 = Benign\n",
        "\n",
        "# If there are any instances classified as malicious by Model A, proceed with Model B classification.\n",
        "if is_malicious.any():\n",
        "    # Initialize an array for DoS scores for all test instances.\n",
        "    dos_scores = np.zeros(len(X_test))\n",
        "    # Predict DoS probabilities ONLY for the subset identified as malicious by Model A, using Model B.\n",
        "    dos_scores[is_malicious] = dos_pipeline.predict_proba(X_test[is_malicious])[:, 1]\n",
        "\n",
        "    # For these malicious instances, classify as DoS (1) if the DoS score meets Model B's threshold,\n",
        "    # otherwise classify as Other attack (2).\n",
        "    # The np.where condition maps 0 (Other) to 2 and 1 (DoS) to 1.\n",
        "    tri_pred_hier[is_malicious] = np.where(\n",
        "        dos_scores[is_malicious] >= DOS_THRESHOLD_FOR_DEPLOY, 1, 2\n",
        "    )\n",
        "\n",
        "# Print the classification report for the final hierarchical tri-class predictions.\n",
        "print(\"=== Tri-class (HIERARCHICAL: Model A → Model B) – TEST ===\")\n",
        "print(classification_report(y_tri_test, tri_pred_hier, zero_division=0, target_names=['Benign','DoS','Other']))\n",
        "\n",
        "# Compute and print the confusion matrix for the hierarchical model.\n",
        "cm_hier = confusion_matrix(y_tri_test, tri_pred_hier)\n",
        "print(\"Confusion matrix rows=Actual[Benign,DoS,Other], cols=Pred[Benign,DoS,Other]:\\n\", cm_hier)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RFI7P6kwzpBL"
      },
      "source": [
        "## Section 8: Save Model Artifacts\n",
        "\n",
        "Save all trained models, thresholds, features, and evaluation metrics to disk for later use."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WNAwnUxszpBL",
        "outputId": "30999edd-a5ea-4c8e-8283-5c58aa023517"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✓ Saved all artifacts to ./models/\n"
          ]
        }
      ],
      "source": [
        "os.makedirs(\"models\", exist_ok=True)\n",
        "\n",
        "# Save the trained binary classifier pipeline (Model A for the hierarchical prediction)\n",
        "joblib.dump(bin_pipeline, \"models/rf_bin.joblib\")\n",
        "# Save the deployment threshold for Model A\n",
        "with open(\"models/bin_threshold.json\",\"w\") as f:\n",
        "    json.dump({'threshold': float(BIN_THRESHOLD_FOR_DEPLOY)}, f)\n",
        "\n",
        "# Save the trained flat tri-class classifier pipeline (Model C)\n",
        "joblib.dump(tri_pipeline, \"models/rf_tri.joblib\")\n",
        "\n",
        "# Save the trained DoS vs. Other classifier pipeline (Model B for the hierarchical prediction)\n",
        "joblib.dump(dos_pipeline, \"models/rf_dos_vs_other.joblib\")\n",
        "# Save the deployment threshold for Model B\n",
        "with open(\"models/dos_threshold.json\",\"w\") as f:\n",
        "    json.dump({'threshold': float(DOS_THRESHOLD_FOR_DEPLOY)}, f)\n",
        "\n",
        "# Save the list of selected features used by the models\n",
        "with open(\"models/features.json\",\"w\") as f:\n",
        "    json.dump(selected_features, f)\n",
        "\n",
        "# Save binary classification metrics (from Model A)\n",
        "with open(\"models/metrics_bin.json\",\"w\") as f:\n",
        "    json.dump({\n",
        "        'threshold_deploy': float(BIN_THRESHOLD_FOR_DEPLOY),\n",
        "        'roc_auc': float(bin_roc),\n",
        "        'pr_auc': float(bin_ap),\n",
        "        'confusion_f1': bin_cm_f1.tolist(),\n",
        "        'confusion_prec': bin_cm_prec.tolist()\n",
        "    }, f, indent=2)\n",
        "\n",
        "# Save flat tri-class classification metrics (from Model C)\n",
        "with open(\"models/metrics_tri_flat.json\",\"w\") as f:\n",
        "    json.dump({'confusion_matrix': tri_cm_flat.tolist()}, f, indent=2)\n",
        "\n",
        "# Save hierarchical tri-class classification metrics (from Model A → Model B)\n",
        "with open(\"models/metrics_tri_hier.json\",\"w\") as f:\n",
        "    json.dump({'confusion_matrix': cm_hier.tolist()}, f, indent=2)\n",
        "\n",
        "print(\"✓ Saved all artifacts to ./models/\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uJ03FqZAzpBL"
      },
      "source": [
        "## Section 9: Prediction Functions & Demonstration\n",
        "\n",
        "Load saved models and make predictions on new data. Includes utilities for both flat and hierarchical classification."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "wiKdEH7CzpBL"
      },
      "outputs": [],
      "source": [
        "# -------------------------\n",
        "# Prediction Loading Functions\n",
        "# -------------------------\n",
        "\n",
        "def load_flat_artifacts(art_dir=\"models\"):\n",
        "    \"\"\"\n",
        "    Loads the artifacts required for flat (binary and tri-class) predictions.\n",
        "\n",
        "    Args:\n",
        "        art_dir (str): Directory where model artifacts are stored.\n",
        "\n",
        "    Returns:\n",
        "        tuple: Binary pipeline (Model A), tri-class pipeline (Model C), binary threshold, and feature list.\n",
        "    \"\"\"\n",
        "    pipe_bin = joblib.load(os.path.join(art_dir, \"rf_bin.joblib\"))\n",
        "    pipe_tri = joblib.load(os.path.join(art_dir, \"rf_tri.joblib\"))\n",
        "    with open(os.path.join(art_dir, \"bin_threshold.json\")) as f:\n",
        "        th = json.load(f)['threshold']\n",
        "    with open(os.path.join(art_dir, \"features.json\")) as f:\n",
        "        feats = json.load(f)\n",
        "    return pipe_bin, pipe_tri, th, feats\n",
        "\n",
        "def predict_from_df(df_features: pd.DataFrame, mode=\"both\", art_dir=\"models\"):\n",
        "    \"\"\"\n",
        "    Makes predictions using the flat classification models (Model A or Model C).\n",
        "\n",
        "    Args:\n",
        "        df_features (pd.DataFrame): DataFrame containing features for prediction.\n",
        "        mode (str): \"binary\", \"tri\", or \"both\" to specify which predictions to return.\n",
        "        art_dir (str): Directory where model artifacts are stored.\n",
        "\n",
        "    Returns:\n",
        "        dict: Dictionary containing prediction scores and/or labels.\n",
        "    \"\"\"\n",
        "    pipe_bin, pipe_tri, th, feats = load_flat_artifacts(art_dir)\n",
        "    X = df_features[feats].copy()\n",
        "    out = {}\n",
        "    if mode in (\"binary\",\"both\"):\n",
        "        scores = pipe_bin.predict_proba(X)[:,1]\n",
        "        out[\"binary_scores\"] = scores\n",
        "        out[\"binary_labels\"] = (scores >= th).astype(int)\n",
        "    if mode in (\"tri\",\"both\"):\n",
        "        out[\"tri_labels\"] = pipe_tri.predict(X)\n",
        "    return out\n",
        "\n",
        "def load_hier_artifacts(art_dir=\"models\"):\n",
        "    \"\"\"\n",
        "    Loads the artifacts required for hierarchical predictions (Model A and Model B).\n",
        "\n",
        "    Args:\n",
        "        art_dir (str): Directory where model artifacts are stored.\n",
        "\n",
        "    Returns:\n",
        "        dict: Dictionary containing binary pipeline (Model A), DoS pipeline (Model B),\n",
        "              binary threshold, DoS threshold, and feature list.\n",
        "    \"\"\"\n",
        "    pipe_bin = joblib.load(os.path.join(art_dir, \"rf_bin.joblib\"))\n",
        "    pipe_dos = joblib.load(os.path.join(art_dir, \"rf_dos_vs_other.joblib\"))\n",
        "    with open(os.path.join(art_dir, \"bin_threshold.json\")) as f:\n",
        "        t1 = json.load(f)['threshold']\n",
        "    with open(os.path.join(art_dir, \"dos_threshold.json\")) as f:\n",
        "        t2 = json.load(f)['threshold']\n",
        "    with open(os.path.join(art_dir, \"features.json\")) as f:\n",
        "        feats = json.load(f)\n",
        "    return dict(pipe_bin=pipe_bin, pipe_dos=pipe_dos, t1=t1, t2=t2, feats=feats)\n",
        "\n",
        "def predict_hier_from_df(df_features: pd.DataFrame, art_dir=\"models\"):\n",
        "    \"\"\"\n",
        "    Makes predictions using the hierarchical classification model (Model A followed by Model B).\n",
        "\n",
        "    Args:\n",
        "        df_features (pd.DataFrame): DataFrame containing features for prediction.\n",
        "        art_dir (str): Directory where model artifacts are stored.\n",
        "\n",
        "    Returns:\n",
        "        dict: Dictionary containing binary scores, binary labels, and hierarchical tri-class labels.\n",
        "              The tri-class labels are derived by first applying Model A, then Model B conditionally.\n",
        "    \"\"\"\n",
        "    art = load_hier_artifacts(art_dir)\n",
        "    X = df_features[art['feats']].copy()\n",
        "    # Model A: Predict binary scores (malicious probability) for all instances\n",
        "    s_bin = art['pipe_bin'].predict_proba(X)[:,1]\n",
        "    # Determine if an instance is classified as malicious based on Model A's binary threshold\n",
        "    is_mal = (s_bin >= art['t1'])\n",
        "    # Initialize tri-class predictions, default to Benign (0)\n",
        "    tri = np.zeros(len(X), dtype=int)\n",
        "    if is_mal.any():\n",
        "        # Model B: For instances identified as malicious by Model A, predict DoS scores\n",
        "        s_dos = np.zeros(len(X))\n",
        "        s_dos[is_mal] = art['pipe_dos'].predict_proba(X[is_mal])[:,1]\n",
        "        # Classify malicious instances as DoS (1) or Other (2) based on Model B's DoS threshold\n",
        "        tri[is_mal] = (s_dos[is_mal] >= art['t2']).astype(int) + 1 # 1=DoS, 2=Other\n",
        "    return {\"binary_scores\": s_bin, \"binary_labels\": (s_bin >= art['t1']).astype(int), \"tri_labels\": tri}\n",
        "\n",
        "def save_predictions_csv(df_features: pd.DataFrame, out_csv: str, mode=\"hier\", art_dir=\"models\"):\n",
        "    \"\"\"\n",
        "    Makes predictions using the specified model mode and saves results to CSV.\n",
        "\n",
        "    Args:\n",
        "        df_features (pd.DataFrame): DataFrame containing the input features.\n",
        "        out_csv (str): Path to the output CSV file where predictions will be saved.\n",
        "        mode (str): \"flat\" for flat classification or \"hier\" for hierarchical classification.\n",
        "        art_dir (str): Directory where model artifacts are stored.\n",
        "    \"\"\"\n",
        "    if mode == \"flat\":\n",
        "        out = predict_from_df(df_features, mode='both', art_dir=art_dir)\n",
        "    else:\n",
        "        out = predict_hier_from_df(df_features, art_dir=art_dir)\n",
        "\n",
        "    # Create an output DataFrame with original features and new predictions\n",
        "    df_out = df_features.copy()\n",
        "    if \"binary_scores\" in out:\n",
        "        df_out[\"bin_prob_mal\"] = out[\"binary_scores\"]\n",
        "        df_out[\"bin_label\"]    = out[\"binary_labels\"]\n",
        "    if \"tri_labels\" in out:\n",
        "        df_out[\"tri_label\"]    = out[\"tri_labels\"]\n",
        "\n",
        "    # Save the predictions to a CSV file\n",
        "    df_out.to_csv(out_csv, index=False)\n",
        "    print(\"Saved:\", out_csv)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7EyPNU9hzpBL",
        "outputId": "5b1577b6-31d6-43a8-d12b-31445a9d4a1a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Testing prediction functions on sample data:\n",
            "\n",
            "Flat prediction keys: dict_keys(['binary_scores', 'binary_labels', 'tri_labels'])\n",
            "Hierarchical prediction keys: dict_keys(['binary_scores', 'binary_labels', 'tri_labels'])\n",
            "\n",
            "============================================================\n",
            "Generating prediction CSV previews...\n",
            "============================================================\n",
            "Saved: predictions_preview_flat.csv\n",
            "Saved: predictions_preview_hier.csv\n",
            "\n",
            "✓ Demo complete! Prediction utilities are ready for use.\n"
          ]
        }
      ],
      "source": [
        "# -------------------------\n",
        "# Prediction Demo\n",
        "# -------------------------\n",
        "\n",
        "print(\"Testing prediction functions on sample data:\")\n",
        "print(\"\\nFlat prediction keys:\", predict_from_df(df_test[selected_features].head(5), mode=\"both\").keys())\n",
        "print(\"Hierarchical prediction keys:\", predict_hier_from_df(df_test[selected_features].head(5)).keys())\n",
        "\n",
        "# Generate prediction previews using 200 rows of test data\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"Generating prediction CSV previews...\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "save_predictions_csv(df_test[selected_features].head(200), \"predictions_preview_flat.csv\", mode=\"flat\")\n",
        "save_predictions_csv(df_test[selected_features].head(200), \"predictions_preview_hier.csv\", mode=\"hier\")\n",
        "\n",
        "print(\"\\n✓ Demo complete! Prediction utilities are ready for use.\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}